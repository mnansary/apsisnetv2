{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# change able params\n",
    "#------------------------------\n",
    "PRETRAINED_WEIGHT_DIR   = \"/home/nazmuddoha_ansary/work/apsisnetv2/model/robust_scanner/\"\n",
    "\n",
    "TRAIN_GCS_PATTERNS      = [\"/home/nazmuddoha_ansary/work/apsisnetv2/tfrecords/*/*/*.tfrecord\"]\n",
    "                           \n",
    "EVAL_GCS_PATTERNS       = [\"/home/nazmuddoha_ansary/work/apsisnetv2/tfrecords/part_0/*/*.tfrecord\"]\n",
    "\n",
    "PER_REPLICA_BATCH_SIZE  = 32                          \n",
    "\n",
    "EPOCHS                  = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e40495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# imports\n",
    "#---------------\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#---------------------\n",
    "# suppress warnings\n",
    "#---------------------\n",
    "# Set TensorFlow logging level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all but error messages\n",
    "# Suppress warnings globally\n",
    "warnings.filterwarnings('ignore')\n",
    "# Customize TensorFlow logger to show only errors\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "#---------------------\n",
    "# GPU device setup\n",
    "#---------------------\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for each GPU\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before initializing GPUs\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "\n",
    "model_dir=os.path.join(os.getcwd(),\"model\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec281ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# semi-fixed parameters\n",
    "#------------------------------------------------------------------------\n",
    "img_width =256\n",
    "img_height=32\n",
    "pos_max   =40\n",
    "tf_size   =1024\n",
    "vocab    = [\"blank\",\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\"0\",\"1\",\"2\",\"3\",\n",
    "            \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\n",
    "            \"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"[\",\n",
    "            \"\\\\\",\"]\",\"^\",\"_\",\"`\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\n",
    "            \"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\",\"{\",\"|\",\"}\",\"~\",\"।\",\"ঁ\",\"ং\",\"ঃ\",\"অ\",\n",
    "            \"আ\",\"ই\",\"ঈ\",\"উ\",\"ঊ\",\"ঋ\",\"এ\",\"ঐ\",\"ও\",\"ঔ\",\"ক\",\"খ\",\"গ\",\"ঘ\",\"ঙ\",\"চ\",\"ছ\",\"জ\",\"ঝ\",\"ঞ\",\n",
    "            \"ট\",\"ঠ\",\"ড\",\"ঢ\",\"ণ\",\"ত\",\"থ\",\"দ\",\"ধ\",\"ন\",\"প\",\"ফ\",\"ব\",\"ভ\",\"ম\",\"য\",\"র\",\"ল\",\"শ\",\"ষ\",\n",
    "            \"স\",\"হ\",\"া\",\"ি\",\"ী\",\"ু\",\"ূ\",\"ৃ\",\"ে\",\"ৈ\",\"ো\",\"ৌ\",\"্\",\"ৎ\",\"ড়\",\"ঢ়\",\"য়\",\"০\",\"১\",\"২\",\n",
    "            \"৩\",\"৪\",\"৫\",\"৬\",\"৭\",\"৮\",\"৯\",\"‍\",\"sep\",\"pad\"]\n",
    "\n",
    "#-------------------\n",
    "# fixed params\n",
    "#------------------\n",
    "nb_channels =  3        \n",
    "enc_filters =  256\n",
    "factor      =  32\n",
    "\n",
    "# calculated\n",
    "enc_shape   =  (img_height//factor,img_width//factor, enc_filters )\n",
    "attn_shape  =  (None, enc_filters )\n",
    "mask_len    =  int((img_width//factor)*(img_height//factor))\n",
    "\n",
    "sep_value   =  vocab.index(\"sep\")\n",
    "pad_value   =  vocab.index(\"pad\")\n",
    "voc_len     =  len(vocab)\n",
    "\n",
    "print(\"Label len:\",pos_max)\n",
    "print(\"Vocab len:\",voc_len)\n",
    "print(\"Pad value:\",pad_value)\n",
    "print(\"Sep value:\",sep_value)\n",
    "\n",
    "#--------------------------\n",
    "# GCS Paths and tfrecords\n",
    "#-------------------------\n",
    "train_recs=[]\n",
    "eval_recs =[]\n",
    "def get_tfrecs(gcs_pattern):\n",
    "    file_paths = tf.io.gfile.glob(gcs_pattern)\n",
    "    random.shuffle(file_paths)\n",
    "    print(len(file_paths))\n",
    "    return file_paths\n",
    "\n",
    "for gcs in TRAIN_GCS_PATTERNS:\n",
    "    print(gcs)\n",
    "    train_recs+=get_tfrecs(gcs)\n",
    "for gcs in EVAL_GCS_PATTERNS:\n",
    "    print(gcs)\n",
    "    eval_recs+=get_tfrecs(gcs)\n",
    "# exclude evals\n",
    "train_recs=[rec for rec in train_recs if rec not in eval_recs]\n",
    "print(\"Eval-recs:\",len(eval_recs))\n",
    "print(\"Train-recs:\",len(train_recs))\n",
    "#----------------------------------------------------------\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "#----------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy() \n",
    "# default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "#-------------------------------------\n",
    "# batching , strategy and steps\n",
    "#-------------------------------------\n",
    "BATCH_SIZE = PER_REPLICA_BATCH_SIZE\n",
    "# set    \n",
    "STEPS_PER_EPOCH = (len(train_recs)*tf_size)//BATCH_SIZE\n",
    "EVAL_STEPS      = (len(eval_recs)*tf_size)//BATCH_SIZE\n",
    "DECAY_STEPS     = EPOCHS * (STEPS_PER_EPOCH+EVAL_STEPS) \n",
    "print(\"Steps:\",STEPS_PER_EPOCH)\n",
    "print(\"Batch Size:\",BATCH_SIZE)\n",
    "print(\"Eval Steps:\",EVAL_STEPS)\n",
    "print(\"Decay Steps:\",DECAY_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T21:38:47.723855Z",
     "iopub.status.busy": "2024-07-25T21:38:47.723441Z",
     "iopub.status.idle": "2024-07-25T21:38:48.121202Z",
     "shell.execute_reply": "2024-07-25T21:38:48.120404Z",
     "shell.execute_reply.started": "2024-07-25T21:38:47.723825Z"
    },
    "papermill": {
     "duration": 0.30737,
     "end_time": "2024-03-30T03:41:40.793596",
     "exception": false,
     "start_time": "2024-03-30T03:41:40.486226",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# parsing tfrecords basic\n",
    "#------------------------------\n",
    "\n",
    "def data_input_fn(recs,mode): \n",
    "    '''\n",
    "      This Function generates data from gcs\n",
    "      * The parser function should look similiar now because of datasetEDA\n",
    "    '''\n",
    "    def _parser(example):   \n",
    "        feature ={  'image' : tf.io.FixedLenFeature([],tf.string) ,\n",
    "                    'mask' : tf.io.FixedLenFeature([],tf.string),\n",
    "                    'std' : tf.io.FixedLenFeature([],tf.string),\n",
    "                    'label':  tf.io.FixedLenFeature([],tf.string),\n",
    "                    'lang':  tf.io.FixedLenFeature([],tf.string),\n",
    "\n",
    "        }    \n",
    "        parsed_example=tf.io.parse_single_example(example,feature)\n",
    "                # image\n",
    "        image_raw=parsed_example['image']\n",
    "        image=tf.image.decode_png(image_raw,channels=nb_channels)\n",
    "        image=tf.cast(image,tf.float32)/255.0\n",
    "        image=tf.reshape(image,(img_height,img_width,nb_channels))\n",
    "        # label\n",
    "        label=parsed_example['label']\n",
    "        label = tf.strings.to_number(tf.strings.split(label), out_type=tf.float32)\n",
    "        # position\n",
    "        pos=tf.range(0,pos_max)\n",
    "        pos=tf.cast(pos,tf.int32)\n",
    "        # mask\n",
    "        mask=parsed_example['mask']\n",
    "        mask=tf.image.decode_png(mask,channels=1)\n",
    "        mask=tf.cast(mask,tf.float32)/255.0\n",
    "        mask=tf.reshape(mask,(img_height,img_width,1))\n",
    "        mask=tf.image.resize(mask,[img_height//factor,img_width//factor],method=\"nearest\")\n",
    "        mask=tf.reshape(mask,[-1])\n",
    "        mask=tf.stack([mask for _ in range(pos_max)])\n",
    "        return {\"image\":image,\"label\":tf.cast(label, tf.int32),\"pos\":pos,\"mask\":mask},label\n",
    "\n",
    "\n",
    "    # fixed code (for almost all tfrec training)\n",
    "    dataset = tf.data.TFRecordDataset(recs)\n",
    "    dataset = dataset.map(_parser,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(1024,reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.apply(tf.data.experimental.ignore_errors())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# train ds\n",
    "train_ds  =   data_input_fn(train_recs,\"train\")\n",
    "\n",
    "# validation ds\n",
    "eval_ds  =   data_input_fn(eval_recs,\"eval\")\n",
    "\n",
    "#------------------------\n",
    "# visualizing data\n",
    "#------------------------\n",
    "\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"visualizing data\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "for x,y in train_ds.take(1):\n",
    "    data=np.squeeze(x[\"image\"][0])\n",
    "    plt.imshow(data)\n",
    "    plt.show()\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"label:\",x[\"label\"][0])\n",
    "    _label=x['label'][0].numpy()\n",
    "    text=\"\".join([vocab[int(c)] for c in _label if vocab[int(c)] not in [\"pad\",\"sep\"]])\n",
    "    print(\"label-text :\",text)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"pos:\",x[\"pos\"][0])\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"mask:\",x[\"mask\"][0][0])\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print('Image Batch Shape:',x[\"image\"].shape)\n",
    "    print('Label Batch Shape:',x[\"label\"].shape)\n",
    "    print('Position Batch Shape:',x[\"pos\"].shape)\n",
    "    print('Mask Batch Shape:',x[\"mask\"].shape)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print('Target Batch Shape:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006451,
     "end_time": "2024-03-30T03:41:41.495930",
     "exception": false,
     "start_time": "2024-03-30T03:41:41.489479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T21:38:48.855370Z",
     "iopub.status.busy": "2024-07-25T21:38:48.855023Z",
     "iopub.status.idle": "2024-07-25T21:38:50.743392Z",
     "shell.execute_reply": "2024-07-25T21:38:50.742121Z",
     "shell.execute_reply.started": "2024-07-25T21:38:48.855340Z"
    },
    "papermill": {
     "duration": 0.148712,
     "end_time": "2024-03-30T03:41:41.650807",
     "exception": false,
     "start_time": "2024-03-30T03:41:41.502095",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# pretrained weights paths\n",
    "#------------------------------\n",
    "enc_weights             = os.path.join(PRETRAINED_WEIGHT_DIR ,\"enc.h5\")\n",
    "seq_weights             = os.path.join(PRETRAINED_WEIGHT_DIR ,\"seq.h5\")\n",
    "pos_weights             = os.path.join(PRETRAINED_WEIGHT_DIR ,\"pos.h5\")\n",
    "fuse_weights            = os.path.join(PRETRAINED_WEIGHT_DIR ,\"fuse.h5\")\n",
    "\n",
    "#-----------------------------------\n",
    "#creating Embedding Weights\n",
    "#-----------------------------------\n",
    "seq_emb              = nn.Embedding(voc_len+1,enc_filters, padding_idx=pad_value)\n",
    "seq_emb_weight       = seq_emb.weight.data.numpy()\n",
    "pos_emb              = nn.Embedding(pos_max+1,enc_filters)\n",
    "pos_emb_weight       = pos_emb.weight.data.numpy()\n",
    "\n",
    "#---------------------------------------------------\n",
    "# dot attention layer\n",
    "#---------------------------------------------------\n",
    "class DotAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "        Calculate the attention weights.\n",
    "        q, k, v must have matching leading dimensions.\n",
    "        k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "        The mask has different shapes depending on its type(padding or look ahead)\n",
    "        but it must be broadcastable for addition.\n",
    "\n",
    "        Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable\n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "        output\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inf_val=-1e9\n",
    "        \n",
    "    def call(self,q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "       \n",
    "        # scale matmul_qk\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        # add the mask to the scaled tensor.\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * self.inf_val)\n",
    "\n",
    "        # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "        # add up to 1.\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def encoder():\n",
    "    '''\n",
    "    creates the encoder part:\n",
    "    * defatult backbone : DenseNet121 **changeable\n",
    "    args:\n",
    "      img           : input image layer\n",
    "        \n",
    "    returns:\n",
    "      enc           : channel reduced feature layer\n",
    "\n",
    "    '''\n",
    "    # img input\n",
    "    img=tf.keras.Input(shape=(img_height,img_width,nb_channels),name='image')\n",
    "    \n",
    "    cnn = tf.keras.applications.ResNet50V2(input_tensor=img,weights=None,include_top=False)\n",
    "    enc = cnn.output\n",
    "    # enc \n",
    "    enc=tf.keras.layers.Conv2D(enc_filters,kernel_size=3,padding=\"same\")(enc)\n",
    "\n",
    "    return tf.keras.Model(inputs=img,outputs=enc,name=\"rs_encoder\")\n",
    "\n",
    "def seq_decoder():\n",
    "    '''\n",
    "    sequence attention decoder (for training)\n",
    "    Tensorflow implementation of : \n",
    "    https://github.com/open-mmlab/mmocr/blob/main/mmocr/models/textrecog/decoders/sequence_attention_decoder.py\n",
    "    '''\n",
    "    # label input\n",
    "    gt=tf.keras.Input(shape=(pos_max,),dtype='int32',name=\"label\")\n",
    "    # mask\n",
    "    mask=tf.keras.Input(shape=(pos_max,mask_len),dtype='float32',name=\"mask\")\n",
    "    # encoder\n",
    "    enc=tf.keras.Input(shape=enc_shape,name='enc_seq')\n",
    "    # embedding\n",
    "    embedding=tf.keras.layers.Embedding(voc_len+1,enc_filters,weights=[seq_emb_weight])(gt)\n",
    "    # sequence layer (2xlstm)\n",
    "    lstm=tf.keras.layers.LSTM(enc_filters,return_sequences=True)(embedding)\n",
    "    query=tf.keras.layers.LSTM(enc_filters,return_sequences=True)(lstm)\n",
    "    # attention modeling\n",
    "    # value\n",
    "    bs,h,w,nc=enc.shape\n",
    "    value=tf.keras.layers.Reshape((h*w,nc))(enc)\n",
    "    attn=DotAttention()(query,value,value,mask)\n",
    "    return tf.keras.Model(inputs=[gt,enc,mask],outputs=attn,name=\"rs_seq_decoder\")\n",
    " \n",
    "\n",
    "\n",
    "def pos_decoder():\n",
    "    '''\n",
    "    position attention decoder (for training)\n",
    "    Tensorflow implementation of : \n",
    "    https://github.com/open-mmlab/mmocr/blob/main/mmocr/models/textrecog/decoders/position_attention_decoder.py\n",
    "    '''\n",
    "    # pos input\n",
    "    pt=tf.keras.Input(shape=(pos_max,),dtype='int32',name=\"pos\")\n",
    "    # mask\n",
    "    mask=tf.keras.Input(shape=(pos_max,mask_len),dtype='float32',name=\"mask\")\n",
    "    # encoder\n",
    "    enc=tf.keras.Input(shape=enc_shape,name='enc_pos')\n",
    "    \n",
    "    # embedding,weights=[pos_emb_weight]\n",
    "    query=tf.keras.layers.Embedding(pos_max+1,enc_filters,weights=[pos_emb_weight])(pt)\n",
    "    # part-1:position_aware_module\n",
    "    bs,h,w,nc=enc.shape\n",
    "    value=tf.keras.layers.Reshape((h*w,nc))(enc)\n",
    "    # sequence layer (2xlstm)\n",
    "    lstm=tf.keras.layers.LSTM(enc_filters,return_sequences=True)(value)\n",
    "    x=tf.keras.layers.LSTM(enc_filters,return_sequences=True)(lstm)\n",
    "    x=tf.keras.layers.Reshape((h,w,nc))(x)\n",
    "    # mixer\n",
    "    x=tf.keras.layers.Conv2D(enc_filters,kernel_size=3,padding=\"same\")(x)\n",
    "    x=tf.keras.layers.Activation(\"relu\")(x)\n",
    "    key=tf.keras.layers.Conv2D(enc_filters,kernel_size=3,padding=\"same\")(x)\n",
    "    bs,h,w,c=key.shape\n",
    "    key=tf.keras.layers.Reshape((h*w,nc))(key)\n",
    "    attn=DotAttention()(query,key,value,mask)\n",
    "    return tf.keras.Model(inputs=[pt,enc,mask],outputs=attn,name=\"rs_pos_decoder\")\n",
    "\n",
    "def fusion():\n",
    "    '''\n",
    "    fuse the output of gt_attn and pt_attn \n",
    "    '''\n",
    "    # label input\n",
    "    gt_attn=tf.keras.Input(shape=attn_shape,name=\"gt_attn\")\n",
    "    # pos input\n",
    "    pt_attn=tf.keras.Input(shape=attn_shape,name=\"pt_attn\")\n",
    "    \n",
    "    x=tf.keras.layers.Concatenate()([gt_attn,pt_attn])\n",
    "    # Linear\n",
    "    x=tf.keras.layers.Dense(enc_filters*2,activation=None)(x)\n",
    "    # GLU\n",
    "    xl=tf.keras.layers.Activation(\"linear\")(x)\n",
    "    xs=tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "    x =tf.keras.layers.Multiply()([xl,xs])\n",
    "    # prediction\n",
    "    x=tf.keras.layers.Dense(voc_len,activation=None)(x)\n",
    "    return tf.keras.Model(inputs=[gt_attn,pt_attn],outputs=x,name=\"rs_fusion\")\n",
    "\n",
    "with strategy.scope():\n",
    "    rs_encoder    =  encoder()\n",
    "    rs_seq_decoder=  seq_decoder()\n",
    "    rs_pos_decoder=  pos_decoder()\n",
    "    rs_fusion     =  fusion()\n",
    "    if os.path.exists(enc_weights):\n",
    "        rs_encoder.load_weights(enc_weights)\n",
    "        print(\"enc:\",enc_weights)\n",
    "    if os.path.exists(seq_weights):\n",
    "        rs_seq_decoder.load_weights(seq_weights)\n",
    "        print(\"seq:\",seq_weights)\n",
    "    if os.path.exists(pos_weights):\n",
    "        rs_pos_decoder.load_weights(pos_weights)\n",
    "        print(\"pos:\",pos_weights)\n",
    "    if os.path.exists(fuse_weights):\n",
    "        rs_fusion.load_weights(fuse_weights)\n",
    "        print(\"fuse:\",fuse_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T21:38:55.025445Z",
     "iopub.status.busy": "2024-07-25T21:38:55.025170Z",
     "iopub.status.idle": "2024-07-25T21:38:55.034842Z",
     "shell.execute_reply": "2024-07-25T21:38:55.034037Z",
     "shell.execute_reply.started": "2024-07-25T21:38:55.025419Z"
    },
    "papermill": {
     "duration": 19.51324,
     "end_time": "2024-03-30T03:42:23.387118",
     "exception": false,
     "start_time": "2024-03-30T03:42:03.873878",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.0001,\n",
    "                                                 decay_steps=DECAY_STEPS,\n",
    "                                                 alpha= 0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def CE_loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, pad_value))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def C_acc(real, pred):\n",
    "    accuracies = tf.equal(tf.cast(real,tf.int64), tf.argmax(pred, axis=2))\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,pad_value))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T21:38:55.036360Z",
     "iopub.status.busy": "2024-07-25T21:38:55.036101Z",
     "iopub.status.idle": "2024-07-25T21:38:55.052783Z",
     "shell.execute_reply": "2024-07-25T21:38:55.051943Z",
     "shell.execute_reply.started": "2024-07-25T21:38:55.036334Z"
    },
    "papermill": {
     "duration": 0.015385,
     "end_time": "2024-03-30T03:42:23.408708",
     "exception": false,
     "start_time": "2024-03-30T03:42:23.393323",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class robust_scanner(tf.keras.Model):\n",
    "    def __init__(self,encoder,seq_decoder,pos_decoder,fusion):\n",
    "        super(robust_scanner, self).__init__()\n",
    "        self.encoder     = encoder\n",
    "        self.seq_decoder = seq_decoder\n",
    "        self.pos_decoder = pos_decoder\n",
    "        self.fusion      = fusion\n",
    "\n",
    "    def compile(self,optimizer,loss_fn,acc):\n",
    "        super(robust_scanner, self).compile(optimizer=optimizer)\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn   = loss_fn\n",
    "        self.acc       = acc\n",
    "\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        data,gt= batch_data\n",
    "        image=data[\"image\"]\n",
    "        pos  =data[\"pos\"]\n",
    "        mask =data[\"mask\"]\n",
    "        \n",
    "        with tf.GradientTape() as enc_tape, tf.GradientTape() as pos_dec_tape,tf.GradientTape() as seq_dec_tape,tf.GradientTape() as fusion_tape:\n",
    "            enc    = self.encoder(image)\n",
    "            pt_attn= self.pos_decoder([pos,enc,mask])\n",
    "\n",
    "            gt_attn= self.seq_decoder([gt,enc,mask])\n",
    "            pred   = self.fusion([gt_attn,pt_attn])\n",
    "\n",
    "            # loss\n",
    "            loss = self.loss_fn(gt[:,1:],pred[:,:-1,:])\n",
    "            # c acc\n",
    "            char_acc=self.acc(gt[:,1:],pred[:,:-1,:])\n",
    "\n",
    "        # calc gradients    \n",
    "        enc_grads     = enc_tape.gradient(loss,self.encoder.trainable_variables)\n",
    "        pos_dec_grads = pos_dec_tape.gradient(loss,self.pos_decoder.trainable_variables)\n",
    "        seq_dec_grads = seq_dec_tape.gradient(loss,self.seq_decoder.trainable_variables)\n",
    "        fusion_grads  = fusion_tape.gradient(loss,self.fusion.trainable_variables)\n",
    "\n",
    "        # apply\n",
    "        self.optimizer.apply_gradients(zip(enc_grads,self.encoder.trainable_variables))\n",
    "        self.optimizer.apply_gradients(zip(pos_dec_grads,self.pos_decoder.trainable_variables))\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(seq_dec_grads,self.seq_decoder.trainable_variables))\n",
    "        self.optimizer.apply_gradients(zip(fusion_grads,self.fusion.trainable_variables))\n",
    "\n",
    "\n",
    "        return {\"loss\"    : loss,\n",
    "                \"char_acc\": char_acc}\n",
    "\n",
    "    def test_step(self, batch_data):\n",
    "        data,gt= batch_data\n",
    "        image=data[\"image\"]\n",
    "        pos  =data[\"pos\"]\n",
    "        mask =data[\"mask\"]\n",
    "        # label\n",
    "        label=tf.ones_like(gt,dtype=tf.float32)*sep_value\n",
    "        preds=[]\n",
    "\n",
    "        enc    = self.encoder(image, training=False)\n",
    "        pt_attn= self.pos_decoder([pos,enc,mask],training=False)\n",
    "\n",
    "        for i in range(pos_max):\n",
    "            gt_attn=self.seq_decoder([label,enc,mask],training=False)\n",
    "            step_gt_attn=gt_attn[:,i,:]\n",
    "            step_pt_attn=pt_attn[:,i,:]\n",
    "            pred=self.fusion([step_gt_attn,step_pt_attn],training=False)\n",
    "            preds.append(pred)\n",
    "            # can change on error\n",
    "            char_out=tf.nn.softmax(pred,axis=-1)\n",
    "            max_idx =tf.math.argmax(char_out,axis=-1)\n",
    "            if i < pos_max - 1:\n",
    "                label=tf.unstack(label,axis=-1)\n",
    "                label[i+1]=tf.cast(max_idx,tf.float32)\n",
    "                label=tf.stack(label,axis=-1)\n",
    "\n",
    "        pred=tf.stack(preds,axis=1)\n",
    "        # loss\n",
    "        loss = self.loss_fn(gt[:,1:],pred[:,:-1,:])\n",
    "        # c acc\n",
    "        char_acc=self.acc(gt[:,1:],pred[:,:-1,:])\n",
    "\n",
    "\n",
    "        return {\"loss\"    : loss,\n",
    "                \"char_acc\": char_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T21:38:55.054015Z",
     "iopub.status.busy": "2024-07-25T21:38:55.053782Z",
     "iopub.status.idle": "2024-07-25T21:38:55.069488Z",
     "shell.execute_reply": "2024-07-25T21:38:55.068659Z",
     "shell.execute_reply.started": "2024-07-25T21:38:55.053991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = robust_scanner(rs_encoder,\n",
    "                           rs_seq_decoder,\n",
    "                           rs_pos_decoder,\n",
    "                           rs_fusion)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss_fn   = CE_loss,\n",
    "              acc       = C_acc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T21:38:55.071851Z",
     "iopub.status.busy": "2024-07-25T21:38:55.071589Z",
     "iopub.status.idle": "2024-07-25T21:38:55.079826Z",
     "shell.execute_reply": "2024-07-25T21:38:55.078693Z",
     "shell.execute_reply.started": "2024-07-25T21:38:55.071826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs['val_loss']\n",
    "        if metric_value < self.best:\n",
    "            print(f\"Loss Improved epoch:{epoch} from {self.best} to {metric_value}\")\n",
    "            self.best = metric_value\n",
    "            self.model_to_save.encoder.save_weights(enc_weights)\n",
    "            self.model_to_save.seq_decoder.save_weights(seq_weights)\n",
    "            self.model_to_save.pos_decoder.save_weights(pos_weights)\n",
    "            self.model_to_save.fusion.save_weights(fuse_weights)\n",
    "            print(\"Saved Weights\")\n",
    "    def set_model(self, model):\n",
    "        self.model_to_save = model  # Assign the model to a different attribute\n",
    "\n",
    "            \n",
    "model_save=SaveBestModel()\n",
    "model_save.set_model(model)\n",
    "callbacks= [model_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T21:38:55.081192Z",
     "iopub.status.busy": "2024-07-25T21:38:55.080946Z",
     "iopub.status.idle": "2024-07-25T21:39:06.627132Z",
     "shell.execute_reply": "2024-07-25T21:39:06.625792Z",
     "shell.execute_reply.started": "2024-07-25T21:38:55.081167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history=model.fit(train_ds,\n",
    "                  epochs=EPOCHS,\n",
    "                  steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                  verbose=1,\n",
    "                  validation_data=eval_ds,\n",
    "                  validation_steps=EVAL_STEPS, \n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-25T21:39:06.628227Z",
     "iopub.status.idle": "2024-07-25T21:39:06.628630Z",
     "shell.execute_reply": "2024-07-25T21:39:06.628457Z",
     "shell.execute_reply.started": "2024-07-25T21:39:06.628439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "curves={}\n",
    "for key in history.history.keys():\n",
    "    curves[key]=history.history[key]\n",
    "curves=pd.DataFrame(curves)\n",
    "curves.to_csv(f\"history_robust_scanner_20_epochs.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 4080924,
     "sourceId": 7083450,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4087190,
     "sourceId": 7092339,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4093113,
     "sourceId": 7100616,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4095951,
     "sourceId": 7104878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4097564,
     "sourceId": 7107275,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4097566,
     "sourceId": 7107278,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30748,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "apsisnetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19621.357396,
   "end_time": "2024-03-30T09:08:12.175701",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-30T03:41:10.818305",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
