{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables That needs to be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# change able params\n",
    "#------------------------------\n",
    "RECOGNIZER_WEIGHT_PATH  = \"/home/nazmuddoha_ansary/work/apsisnetv2/model/rec_2_epochs_2nd_stage.h5\"\n",
    "\n",
    "GENERATOR_WEIGHT_PATH    = \"/home/nazmuddoha_ansary/work/apsisnetv2/model/model.h5\"\n",
    "\n",
    "TRAIN_GCS_PATTERNS      = [\"/backup2/apsisnetv2/tfrecords/*/*/*.tfrecord\"]\n",
    "                           \n",
    "EVAL_GCS_PATTERNS       = [\"/backup2/apsisnetv2/tfrecords/part_0/*/*.tfrecord\"]\n",
    "\n",
    "PER_REPLICA_BATCH_SIZE  = 64                         \n",
    "\n",
    "EPOCHS                  = 5\n",
    "\n",
    "GENERATOR_BACKBONE      = 'densenet121'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No need to change anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* imports\n",
    "* warning suppression\n",
    "* GPU device setup\n",
    "* segmentation model backend setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# imports\n",
    "#---------------\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#---------------------\n",
    "# suppress warnings\n",
    "#---------------------\n",
    "# Set TensorFlow logging level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all but error messages\n",
    "# Suppress warnings globally\n",
    "warnings.filterwarnings('ignore')\n",
    "# Customize TensorFlow logger to show only errors\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "#-----------------------------------------\n",
    "# segmentation model backend setup\n",
    "#-----------------------------------------\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import segmentation_models as sm\n",
    "#---------------------\n",
    "# GPU device setup\n",
    "#---------------------\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for each GPU\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before initializing GPUs\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "\n",
    "model_dir=os.path.join(os.getcwd(),\"model\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fixed and semi fixed parameters\n",
    "* GCS Paths and tfrecords\n",
    "* batching , strategy and steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# semi-fixed parameters\n",
    "#------------------------------------------------------------------------\n",
    "img_width =256\n",
    "img_height=32\n",
    "pos_max   =40\n",
    "tf_size   =1024\n",
    "vocab    = [\"\\u200d\",\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\"0\",\"1\",\"2\",\"3\",\n",
    "            \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\n",
    "            \"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"[\",\n",
    "            \"\\\\\",\"]\",\"^\",\"_\",\"`\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\n",
    "            \"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\",\"{\",\"|\",\"}\",\"~\",\"।\",\"ঁ\",\"ং\",\"ঃ\",\"অ\",\n",
    "            \"আ\",\"ই\",\"ঈ\",\"উ\",\"ঊ\",\"ঋ\",\"এ\",\"ঐ\",\"ও\",\"ঔ\",\"ক\",\"খ\",\"গ\",\"ঘ\",\"ঙ\",\"চ\",\"ছ\",\"জ\",\"ঝ\",\"ঞ\",\n",
    "            \"ট\",\"ঠ\",\"ড\",\"ঢ\",\"ণ\",\"ত\",\"থ\",\"দ\",\"ধ\",\"ন\",\"প\",\"ফ\",\"ব\",\"ভ\",\"ম\",\"য\",\"র\",\"ল\",\"শ\",\"ষ\",\n",
    "            \"স\",\"হ\",\"া\",\"ি\",\"ী\",\"ু\",\"ূ\",\"ৃ\",\"ে\",\"ৈ\",\"ো\",\"ৌ\",\"্\",\"ৎ\",\"ড়\",\"ঢ়\",\"য়\",\"০\",\"১\",\"২\",\n",
    "            \"৩\",\"৪\",\"৫\",\"৬\",\"৭\",\"৮\",\"৯\",\"‍\",\"sep\",\"pad\"]\n",
    "#-------------------\n",
    "# fixed params\n",
    "#------------------\n",
    "nb_channels =  3    \n",
    "enc_filters =  512\n",
    "\n",
    "# calculated\n",
    "pad_value   =  vocab.index(\"pad\")\n",
    "sep_value   =  vocab.index(\"sep\") \n",
    "voc_len     =  len(vocab)\n",
    "\n",
    "pos_emb              = nn.Embedding(pos_max+1,enc_filters)\n",
    "pos_emb_weights      = pos_emb.weight.data.numpy()\n",
    "\n",
    "print(\"Label len:\",pos_max)\n",
    "print(\"Vocab len:\",voc_len)\n",
    "print(\"Pad value:\",pad_value)\n",
    "print(\"pos embedding shape:\",pos_emb_weights.shape)\n",
    "\n",
    "#--------------------------\n",
    "# GCS Paths and tfrecords\n",
    "#-------------------------\n",
    "train_recs=[]\n",
    "eval_recs =[]\n",
    "def get_tfrecs(gcs_pattern):\n",
    "    file_paths = tf.io.gfile.glob(gcs_pattern)\n",
    "    random.shuffle(file_paths)\n",
    "    print(len(file_paths))\n",
    "    return file_paths\n",
    "\n",
    "for gcs in TRAIN_GCS_PATTERNS:\n",
    "    print(gcs)\n",
    "    train_recs+=get_tfrecs(gcs)\n",
    "for gcs in EVAL_GCS_PATTERNS:\n",
    "    print(gcs)\n",
    "    eval_recs+=get_tfrecs(gcs)\n",
    "# exclude evals\n",
    "train_recs=[rec for rec in train_recs if rec not in eval_recs]\n",
    "print(\"Eval-recs:\",len(eval_recs))\n",
    "print(\"Train-recs:\",len(train_recs))\n",
    "#----------------------------------------------------------\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "#----------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy() \n",
    "# default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "#-------------------------------------\n",
    "# batching , strategy and steps\n",
    "#-------------------------------------\n",
    "BATCH_SIZE = PER_REPLICA_BATCH_SIZE\n",
    "# set    \n",
    "STEPS_PER_EPOCH = (len(train_recs)*tf_size)//BATCH_SIZE\n",
    "EVAL_STEPS      = (len(eval_recs)*tf_size)//BATCH_SIZE\n",
    "print(\"Steps:\",STEPS_PER_EPOCH)\n",
    "print(\"Batch Size:\",BATCH_SIZE)\n",
    "print(\"Eval Steps:\",EVAL_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dataset parsing\n",
    "* data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# parsing tfrecords basic\n",
    "#------------------------------\n",
    "def data_input_fn(recs,mode): \n",
    "    '''\n",
    "      This Function generates data from gcs\n",
    "      * The parser function should look similiar now because of datasetEDA\n",
    "        \n",
    "        #         # mask\n",
    "        #         mask=parsed_example['mask']\n",
    "        #         mask=tf.image.decode_png(mask,channels=1)\n",
    "        #         mask=tf.cast(mask,tf.float32)/255.0\n",
    "        #         mask=tf.reshape(mask,(img_height,img_width,1))\n",
    "        #         # lang\n",
    "        #         lang=parsed_example['lang']\n",
    "        #         lang = tf.strings.to_number(tf.strings.split(lang), out_type=tf.float32)\n",
    "        #         lang = tf.reshape(lang,(1,))   \n",
    "\n",
    "        #         return image,mask,std,label,lang\n",
    "        #         return {\"image\":image,\"mask\":mask, \"std\": std, \"lang\": lang},label\n",
    "        #         return image, label\n",
    "\n",
    "\n",
    "    '''\n",
    "    def _parser(example):   \n",
    "        feature ={  'image' : tf.io.FixedLenFeature([],tf.string) ,\n",
    "                    'mask' : tf.io.FixedLenFeature([],tf.string),\n",
    "                    'std' : tf.io.FixedLenFeature([],tf.string),\n",
    "                    'label':  tf.io.FixedLenFeature([],tf.string),\n",
    "                    'lang':  tf.io.FixedLenFeature([],tf.string),\n",
    "                  \n",
    "        }    \n",
    "        parsed_example=tf.io.parse_single_example(example,feature)\n",
    "        # image\n",
    "        image=parsed_example['image']\n",
    "        image=tf.image.decode_png(image,channels=nb_channels)\n",
    "        image=tf.cast(image,tf.float32)/255.0\n",
    "        image=tf.reshape(image,(img_height,img_width,nb_channels))\n",
    "        image=tf.image.resize(image,[2*img_height,2*img_width])\n",
    "        # std\n",
    "        std=parsed_example['std']\n",
    "        std=tf.image.decode_png(std,channels=nb_channels)\n",
    "        std=tf.cast(std,tf.float32)/255.0\n",
    "        std=tf.reshape(std,(img_height,img_width,nb_channels))\n",
    "        std=tf.image.resize(std,[2*img_height,2*img_width])\n",
    "        \n",
    "        # label\n",
    "        label=parsed_example['label']\n",
    "        label = tf.strings.to_number(tf.strings.split(label), out_type=tf.float32)\n",
    "        label = tf.reshape(label,(pos_max,))\n",
    "        \n",
    "        # position\n",
    "        pos=tf.range(0,pos_max)\n",
    "        pos=tf.cast(pos,tf.int32) \n",
    "        \n",
    "        return image,std,pos,label\n",
    "\n",
    "    \n",
    "    # fixed code (for almost all tfrec training)\n",
    "    dataset = tf.data.TFRecordDataset(recs)\n",
    "    dataset = dataset.map(_parser,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(1024,reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.apply(tf.data.experimental.ignore_errors())\n",
    "    return dataset\n",
    "\n",
    "# train ds\n",
    "train_ds  =   data_input_fn(train_recs,\"train\")\n",
    "\n",
    "# validation ds\n",
    "eval_ds  =   data_input_fn(eval_recs,\"eval\")\n",
    "\n",
    "#------------------------\n",
    "# visualizing data\n",
    "#------------------------\n",
    "langs=[\"bn\",\"en\"]\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"visualizing data\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "for images,stds,poss,labels in train_ds.take(1):\n",
    "    print(\"image\")\n",
    "    data=np.squeeze(images[0])\n",
    "    plt.imshow(data)\n",
    "    plt.show()    \n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    _label=labels[0].numpy()\n",
    "    print(_label)\n",
    "    text=\"\".join([vocab[int(c)] for c in _label if vocab[int(c)] not in [\"pad\",\"sep\"]])\n",
    "    print(\"label :\",text)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print('Batch Shape:',images.shape)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"Positional encoding:\",poss[0])\n",
    "    print(\"std\")\n",
    "    data=np.squeeze(stds[0])\n",
    "    plt.imshow(data)\n",
    "    plt.show()\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* custom layers,blocks,metrics,loss,callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# custom layers\n",
    "#--------------------------------------------\n",
    "\n",
    "class DotAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inf_val=-1e9\n",
    "        \n",
    "    def call(self,q, k, v, mask):\n",
    "        \n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "       \n",
    "        # scale matmul_qk\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        # add the mask to the scaled tensor.\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * self.inf_val)\n",
    "\n",
    "        # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "        # add up to 1.\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "        return output\n",
    "     \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "        \n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_seq,projection_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.projection_dim=projection_dim\n",
    "        self.num_seq = num_seq\n",
    "        self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = tf.keras.layers.Embedding(input_dim=num_seq, output_dim=projection_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        positions = tf.range(start=0, limit=self.num_seq, delta=1)\n",
    "        encoded = self.projection(x) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'num_seq': self.num_seq,\n",
    "                       'projection_dim':self.projection_dim})\n",
    "        return config\n",
    "\n",
    "    \n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.embed_dim=embed_dim\n",
    "        self.num_heads=num_heads\n",
    "        self.ff_dim   =ff_dim\n",
    "\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self,x,mask,training):\n",
    "        attn_output = self.att(query=x,key=x,value=x,attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'embed_dim': self.embed_dim,\n",
    "                       'num_heads': self.num_heads,\n",
    "                       'ff_dim':self.ff_dim})\n",
    "        return config\n",
    "    \n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# custom blocks \n",
    "#--------------------------------------------\n",
    "\n",
    "def ConvBlock(x,filters):\n",
    "    x=tf.keras.layers.Conv2D(filters,3,padding='same')(x)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x=tf.keras.layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def attend(x,mask,num_heads,num_blocks,reshape=True):\n",
    "    bs,h,w,nc=x.shape\n",
    "    x = tf.keras.layers.Reshape((h*w,nc))(x)\n",
    "    x = PositionalEncoding(h*w,nc)(x)\n",
    "    for _ in range(num_blocks):\n",
    "        x=TransformerBlock(embed_dim=nc, num_heads=num_heads,ff_dim=4*nc)(x,mask)\n",
    "    if reshape:\n",
    "        x = tf.keras.layers.Reshape((h,w,nc))(x)\n",
    "    return x\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# metrics and losses\n",
    "#--------------------------------------------------------\n",
    "\n",
    "def rec_acc(y_pred, y_true):\n",
    "    accuracies = tf.equal(tf.cast(y_true,tf.int64), tf.argmax(y_pred, axis=2))\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true,pad_value))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "# loss\n",
    "rec_loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def rec_loss(pred, real):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, pad_value))\n",
    "    loss_ = rec_loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def gen_loss(pred,real):    \n",
    "    return 100*mse(real,pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model building \n",
    "* model compiling \n",
    "* callback setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    img_shape=(img_height,img_width,nb_channels)\n",
    "    img =tf.keras.Input(shape=img_shape,name=\"image\")\n",
    "    pos =tf.keras.Input(shape=(pos_max,),name=\"pos\")\n",
    "    x=ConvBlock(img,64)\n",
    "    x=ConvBlock(x,128)\n",
    "    x=attend(x,None,4,4)\n",
    "    x=ConvBlock(x,256)\n",
    "    x=ConvBlock(x,512)\n",
    "    x=attend(x,None,8,8,reshape=False)\n",
    "    #------------pos encoding------------------\n",
    "    query=tf.keras.layers.Embedding(input_dim=pos_max+1, output_dim=enc_filters,weights=[pos_emb_weights])(pos)\n",
    "    attn=DotAttention()(query,x,x,None)\n",
    "    x=tf.keras.layers.Dense(voc_len,activation=None,name=\"logits\")(attn)\n",
    "    model = tf.keras.Model(inputs=[img,pos],outputs=x)\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    recognizer=build_model()\n",
    "    recognizer.load_weights(RECOGNIZER_WEIGHT_PATH)\n",
    "    generator=sm.Unet(GENERATOR_BACKBONE,input_shape=(2*img_height,2*img_width,3), classes=3,encoder_weights=None)\n",
    "    generator.load_weights(GENERATOR_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApsisNetv2(tf.keras.Model):\n",
    "    def __init__(self,generator,recognizer,loss_factor=1):\n",
    "        super(ApsisNetv2, self).__init__()\n",
    "        self.generator   = generator\n",
    "        self.recognizer  = recognizer\n",
    "        self.loss_factor = loss_factor\n",
    "        \n",
    "    def compile(self,optimizer,loss_recognizer,loss_generator,acc_recognizer):\n",
    "        super(ApsisNetv2, self).compile(optimizer=optimizer)\n",
    "        self.optimizer  = optimizer\n",
    "        self.loss_rec   = loss_recognizer\n",
    "        self.loss_gen   = loss_generator\n",
    "        self.acc_rec    = acc_recognizer\n",
    "        \n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        image,std,pos,gt= batch_data\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            generated    = self.generator(image)\n",
    "            gen_resized  = tf.image.resize(generated,[img_height,img_width])\n",
    "            pred         = self.recognizer({\"image\":gen_resized,\"pos\":pos},training=False)\n",
    "            # loss\n",
    "            loss_gen = self.loss_gen(generated,std)\n",
    "            loss_rec = self.loss_rec(pred,gt)\n",
    "            # acc\n",
    "            acc_rec=self.acc_rec(pred,gt)\n",
    "\n",
    "            loss=loss_gen+self.loss_factor*loss_rec\n",
    "        # calc gradients    \n",
    "        gen_grads     = gen_tape.gradient(loss,self.generator.trainable_variables)\n",
    "        \n",
    "        # apply\n",
    "        self.optimizer.apply_gradients(zip(gen_grads,self.generator.trainable_variables))\n",
    "\n",
    "        return {\"loss_gen\"    : loss_gen,\n",
    "                \"loss_rec\"    : loss_rec,\n",
    "                \"loss\"        : loss,\n",
    "                \"char_acc\": acc_rec}\n",
    "\n",
    "    def test_step(self, batch_data):\n",
    "        image,std,pos,gt= batch_data\n",
    "        \n",
    "        generated    = self.generator(image,training=False)\n",
    "        gen_resized  = tf.image.resize(generated,[img_height,img_width])\n",
    "        pred         = self.recognizer({\"image\":gen_resized,\"pos\":pos},training=False)\n",
    "        \n",
    "        # loss\n",
    "        loss_gen = self.loss_gen(generated,std)\n",
    "        loss_rec = self.loss_rec(pred,gt)\n",
    "        # acc\n",
    "        acc_rec=self.acc_rec(pred,gt)\n",
    "\n",
    "        loss=loss_gen+self.loss_factor*loss_rec\n",
    "        \n",
    "        return {\"loss_gen\"    : loss_gen,\n",
    "                \"loss_rec\"    : loss_rec,\n",
    "                \"loss\"        : loss,\n",
    "                \"char_acc\": acc_rec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.0001,\n",
    "                                                 decay_steps=600000,\n",
    "                                                 alpha= 0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = ApsisNetv2(generator,recognizer)\n",
    "\n",
    "model.compile(optimizer,rec_loss,gen_loss,rec_acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "# callbacks \n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=40, \n",
    "                                                  verbose=1, \n",
    "                                                  mode = 'auto')\n",
    "\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,model_dir):\n",
    "        self.best = 0\n",
    "        self.output_dir = model_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs['val_char_acc']\n",
    "        if metric_value > self.best:\n",
    "            print(f\"Loss Improved epoch:{epoch} from {self.best} to {metric_value}\",end=\"#\")\n",
    "            self.best = metric_value\n",
    "            save_path = os.path.join(self.output_dir, \"generator_best.h5\")\n",
    "            self.model.generator.save_weights(save_path)\n",
    "            print(\"Saved Weights\")\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "# call back setup\n",
    "model_save=SaveBestModel(model_dir)\n",
    "model_save.set_model(model)\n",
    "callbacks = [model_save,early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training \n",
    "* history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_ds,\n",
    "                  epochs=EPOCHS,\n",
    "                  steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                  verbose=1,\n",
    "                  validation_data=eval_ds,\n",
    "                  validation_steps=EVAL_STEPS, \n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curves={}\n",
    "for key in history.history.keys():\n",
    "    curves[key]=history.history[key]\n",
    "curves=pd.DataFrame(curves)\n",
    "curves.to_csv(f\"history.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apsisnetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
