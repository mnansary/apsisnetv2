{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables That needs to be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# change able params\n",
    "#------------------------------\n",
    "PRETRAINED_WEIGHT_PATHS = \"/home/nazmuddoha_ansary/work/apsisnetv2/model/rec_2_epochs_2nd_stage.h5\"\n",
    "\n",
    "TRAIN_GCS_PATTERNS      = [\"/home/nazmuddoha_ansary/work/apsisnetv2/tfrecords/*/*/*.tfrecord\"]\n",
    "                           \n",
    "EVAL_GCS_PATTERNS       = [\"/home/nazmuddoha_ansary/work/apsisnetv2/tfrecords/part_0/*/*.tfrecord\"]\n",
    "\n",
    "PER_REPLICA_BATCH_SIZE  = 32                          \n",
    "\n",
    "EPOCHS                  = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No need to change anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* imports\n",
    "* warning suppression\n",
    "* GPU device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# imports\n",
    "#---------------\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#---------------------\n",
    "# suppress warnings\n",
    "#---------------------\n",
    "# Set TensorFlow logging level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all but error messages\n",
    "# Suppress warnings globally\n",
    "warnings.filterwarnings('ignore')\n",
    "# Customize TensorFlow logger to show only errors\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "#---------------------\n",
    "# GPU device setup\n",
    "#---------------------\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for each GPU\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before initializing GPUs\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "\n",
    "model_dir=os.path.join(os.getcwd(),\"model\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fixed and semi fixed parameters\n",
    "* GCS Paths and tfrecords\n",
    "* batching , strategy and steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# semi-fixed parameters\n",
    "#------------------------------------------------------------------------\n",
    "img_width =256\n",
    "img_height=32\n",
    "pos_max   =40\n",
    "tf_size   =1024\n",
    "vocab    = [\"blank\",\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\"0\",\"1\",\"2\",\"3\",\n",
    "            \"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\n",
    "            \"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"[\",\n",
    "            \"\\\\\",\"]\",\"^\",\"_\",\"`\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\n",
    "            \"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\",\"{\",\"|\",\"}\",\"~\",\"।\",\"ঁ\",\"ং\",\"ঃ\",\"অ\",\n",
    "            \"আ\",\"ই\",\"ঈ\",\"উ\",\"ঊ\",\"ঋ\",\"এ\",\"ঐ\",\"ও\",\"ঔ\",\"ক\",\"খ\",\"গ\",\"ঘ\",\"ঙ\",\"চ\",\"ছ\",\"জ\",\"ঝ\",\"ঞ\",\n",
    "            \"ট\",\"ঠ\",\"ড\",\"ঢ\",\"ণ\",\"ত\",\"থ\",\"দ\",\"ধ\",\"ন\",\"প\",\"ফ\",\"ব\",\"ভ\",\"ম\",\"য\",\"র\",\"ল\",\"শ\",\"ষ\",\n",
    "            \"স\",\"হ\",\"া\",\"ি\",\"ী\",\"ু\",\"ূ\",\"ৃ\",\"ে\",\"ৈ\",\"ো\",\"ৌ\",\"্\",\"ৎ\",\"ড়\",\"ঢ়\",\"য়\",\"০\",\"১\",\"২\",\n",
    "            \"৩\",\"৪\",\"৫\",\"৬\",\"৭\",\"৮\",\"৯\",\"‍\",\"sep\",\"pad\"]\n",
    "#-------------------\n",
    "# fixed params\n",
    "#------------------\n",
    "nb_channels =  3    \n",
    "enc_filters =  512\n",
    "\n",
    "# calculated\n",
    "pad_value   =  vocab.index(\"pad\")\n",
    "voc_len     =  len(vocab)\n",
    "\n",
    "pos_emb              = nn.Embedding(pos_max+1,enc_filters)\n",
    "pos_emb_weights      = pos_emb.weight.data.numpy()\n",
    "\n",
    "print(\"Label len:\",pos_max)\n",
    "print(\"Vocab len:\",voc_len)\n",
    "print(\"Pad value:\",pad_value)\n",
    "print(\"pos embedding shape:\",pos_emb_weights.shape)\n",
    "\n",
    "#--------------------------\n",
    "# GCS Paths and tfrecords\n",
    "#-------------------------\n",
    "train_recs=[]\n",
    "eval_recs =[]\n",
    "def get_tfrecs(gcs_pattern):\n",
    "    file_paths = tf.io.gfile.glob(gcs_pattern)\n",
    "    random.shuffle(file_paths)\n",
    "    print(len(file_paths))\n",
    "    return file_paths\n",
    "\n",
    "for gcs in TRAIN_GCS_PATTERNS:\n",
    "    print(gcs)\n",
    "    train_recs+=get_tfrecs(gcs)\n",
    "for gcs in EVAL_GCS_PATTERNS:\n",
    "    print(gcs)\n",
    "    eval_recs+=get_tfrecs(gcs)\n",
    "# exclude evals\n",
    "train_recs=[rec for rec in train_recs if rec not in eval_recs]\n",
    "print(\"Eval-recs:\",len(eval_recs))\n",
    "print(\"Train-recs:\",len(train_recs))\n",
    "#----------------------------------------------------------\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "#----------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy() \n",
    "# default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "#-------------------------------------\n",
    "# batching , strategy and steps\n",
    "#-------------------------------------\n",
    "BATCH_SIZE = PER_REPLICA_BATCH_SIZE\n",
    "# set    \n",
    "STEPS_PER_EPOCH = (len(train_recs)*tf_size)//BATCH_SIZE\n",
    "EVAL_STEPS      = (len(eval_recs)*tf_size)//BATCH_SIZE\n",
    "DECAY_STEPS     = EPOCHS * (STEPS_PER_EPOCH+EVAL_STEPS) \n",
    "print(\"Steps:\",STEPS_PER_EPOCH)\n",
    "print(\"Batch Size:\",BATCH_SIZE)\n",
    "print(\"Eval Steps:\",EVAL_STEPS)\n",
    "print(\"Decay Steps:\",DECAY_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dataset parsing\n",
    "* data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# parsing tfrecords basic\n",
    "#------------------------------\n",
    "def data_input_fn(recs,mode,threshold = 0.5): \n",
    "    '''\n",
    "      This Function generates data from gcs\n",
    "      * The parser function should look similiar now because of datasetEDA\n",
    "        \n",
    "        #         # mask\n",
    "        #         mask=parsed_example['mask']\n",
    "        #         mask=tf.image.decode_png(mask,channels=1)\n",
    "        #         mask=tf.cast(mask,tf.float32)/255.0\n",
    "        #         mask=tf.reshape(mask,(img_height,img_width,1))\n",
    "        #         # lang\n",
    "        #         lang=parsed_example['lang']\n",
    "        #         lang = tf.strings.to_number(tf.strings.split(lang), out_type=tf.float32)\n",
    "        #         lang = tf.reshape(lang,(1,))   \n",
    "\n",
    "        #         return image,mask,std,label,lang\n",
    "        #         return {\"image\":image,\"mask\":mask, \"std\": std, \"lang\": lang},label\n",
    "        #         return image, label\n",
    "\n",
    "\n",
    "    '''\n",
    "    def _parser(example):   \n",
    "        feature ={  'image' : tf.io.FixedLenFeature([],tf.string) ,\n",
    "                    'mask' : tf.io.FixedLenFeature([],tf.string),\n",
    "                    'std' : tf.io.FixedLenFeature([],tf.string),\n",
    "                    'label':  tf.io.FixedLenFeature([],tf.string),\n",
    "                    'lang':  tf.io.FixedLenFeature([],tf.string),\n",
    "                  \n",
    "        }    \n",
    "        parsed_example=tf.io.parse_single_example(example,feature)\n",
    "        # image\n",
    "        image=parsed_example['image']\n",
    "        image=tf.image.decode_png(image,channels=nb_channels)\n",
    "        image=tf.cast(image,tf.float32)/255.0\n",
    "        #image = tf.where(image> threshold, 1.0, 0.0)\n",
    "        image=tf.reshape(image,(img_height,img_width,nb_channels))\n",
    "        # label\n",
    "        label=parsed_example['label']\n",
    "        label = tf.strings.to_number(tf.strings.split(label), out_type=tf.float32)\n",
    "        label = tf.reshape(label,(pos_max,))\n",
    "        \n",
    "        # position\n",
    "        pos=tf.range(0,pos_max)\n",
    "        pos=tf.cast(pos,tf.int32) \n",
    "        \n",
    "        return {\"image\":image,\"pos\":pos},label\n",
    "\n",
    "    \n",
    "    # fixed code (for almost all tfrec training)\n",
    "    dataset = tf.data.TFRecordDataset(recs)\n",
    "    dataset = dataset.map(_parser,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(1024,reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.apply(tf.data.experimental.ignore_errors())\n",
    "    return dataset\n",
    "\n",
    "# train ds\n",
    "train_ds  =   data_input_fn(train_recs,\"train\")\n",
    "\n",
    "# validation ds\n",
    "eval_ds  =   data_input_fn(eval_recs,\"eval\")\n",
    "\n",
    "#------------------------\n",
    "# visualizing data\n",
    "#------------------------\n",
    "langs=[\"bn\",\"en\"]\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"visualizing data\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "for data,label in train_ds.take(1):\n",
    "    images=data[\"image\"]\n",
    "    posis=data[\"pos\"]\n",
    "    print(\"image\")\n",
    "    data=np.squeeze(images[0])\n",
    "    print(np.unique(images[0]))\n",
    "    plt.imshow(data)\n",
    "    plt.show()    \n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    _label=label[0].numpy()\n",
    "    print(_label)\n",
    "    text=\"\".join([vocab[int(c)] for c in _label if vocab[int(c)] not in [\"pad\",\"sep\"]])\n",
    "    print(\"label :\",text)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print('Batch Shape:',images.shape)\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "#     print(\"Positional encoding:\",posis[0])\n",
    "#     print(\"mask\")\n",
    "#     data=np.squeeze(mask[0])\n",
    "#     plt.imshow(data)\n",
    "#     plt.show()\n",
    "#     print(\"std\")\n",
    "#     data=np.squeeze(std[0])\n",
    "#     plt.imshow(data)\n",
    "#     plt.show()\n",
    "#     print(\"---------------------------------------------------------------\")\n",
    "#     _lang=lang[0].numpy()\n",
    "#     _lang=langs[int(_lang)]\n",
    "#     print(\"lang:\",_lang)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* custom layers,blocks,metrics,loss,callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# custom layers\n",
    "#--------------------------------------------\n",
    "\n",
    "class DotAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inf_val=-1e9\n",
    "        \n",
    "    def call(self,q, k, v, mask):\n",
    "        \n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "       \n",
    "        # scale matmul_qk\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        # add the mask to the scaled tensor.\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * self.inf_val)\n",
    "\n",
    "        # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "        # add up to 1.\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "        return output\n",
    "     \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "        \n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_seq,projection_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.projection_dim=projection_dim\n",
    "        self.num_seq = num_seq\n",
    "        self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = tf.keras.layers.Embedding(input_dim=num_seq, output_dim=projection_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        positions = tf.range(start=0, limit=self.num_seq, delta=1)\n",
    "        encoded = self.projection(x) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'num_seq': self.num_seq,\n",
    "                       'projection_dim':self.projection_dim})\n",
    "        return config\n",
    "\n",
    "    \n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.embed_dim=embed_dim\n",
    "        self.num_heads=num_heads\n",
    "        self.ff_dim   =ff_dim\n",
    "\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self,x,mask,training):\n",
    "        attn_output = self.att(query=x,key=x,value=x,attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'embed_dim': self.embed_dim,\n",
    "                       'num_heads': self.num_heads,\n",
    "                       'ff_dim':self.ff_dim})\n",
    "        return config\n",
    "    \n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# custom blocks \n",
    "#--------------------------------------------\n",
    "\n",
    "def ConvBlock(x,filters):\n",
    "    x=tf.keras.layers.Conv2D(filters,3,padding='same')(x)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x=tf.keras.layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def attend(x,mask,num_heads,num_blocks,reshape=True):\n",
    "    bs,h,w,nc=x.shape\n",
    "    x = tf.keras.layers.Reshape((h*w,nc))(x)\n",
    "    x = PositionalEncoding(h*w,nc)(x)\n",
    "    for _ in range(num_blocks):\n",
    "        x=TransformerBlock(embed_dim=nc, num_heads=num_heads,ff_dim=4*nc)(x,mask)\n",
    "    if reshape:\n",
    "        x = tf.keras.layers.Reshape((h,w,nc))(x)\n",
    "    return x\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# metrics and losses\n",
    "#--------------------------------------------------------\n",
    "\n",
    "def C_acc(y_true, y_pred):\n",
    "    accuracies = tf.equal(tf.cast(y_true,tf.int64), tf.argmax(y_pred, axis=2))\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true,pad_value))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "class CharLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,pad_value):\n",
    "        super(CharLoss, self).__init__(name=\"char_loss\")\n",
    "        self.pad_value=pad_value\n",
    "        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    def call(self, y_true, y_pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(y_true, pad_value))\n",
    "        loss_ = self.loss_object(y_true, y_pred)\n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "    \n",
    "\n",
    "class CTCLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self,pad_value,logits_time_major=False,name='ctc'):\n",
    "        super().__init__(name=name)\n",
    "        self.logits_time_major = logits_time_major\n",
    "        self.pad_value=pad_value\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\n",
    "        label_mask = tf.cast(y_true!= self.pad_value, tf.int32)\n",
    "        label_length = tf.reduce_sum(label_mask, axis=-1)\n",
    "        \n",
    "        loss = tf.nn.ctc_loss(\n",
    "            labels=y_true,\n",
    "            logits=y_pred,\n",
    "            label_length=label_length,\n",
    "            logit_length=logit_length,\n",
    "            logits_time_major=self.logits_time_major,\n",
    "            blank_index=self.pad_value)\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# callbacks \n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=40, \n",
    "                                                  verbose=1, \n",
    "                                                  mode = 'auto')\n",
    "\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,model_dir):\n",
    "        self.best = float('inf')\n",
    "        self.output_dir = model_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs['val_loss']\n",
    "        if metric_value < self.best:\n",
    "            print(f\"Loss Improved epoch:{epoch} from {self.best} to {metric_value}\",end=\"#\")\n",
    "            self.best = metric_value\n",
    "            save_path = os.path.join(self.output_dir, \"rec_best.h5\")\n",
    "            self.model.save_weights(save_path)\n",
    "            print(\"Saved Weights\")\n",
    "    def set_model(self, model):\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model building \n",
    "* model compiling \n",
    "* callback setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    img_shape=(img_height,img_width,nb_channels)\n",
    "    img =tf.keras.Input(shape=img_shape,name=\"image\")\n",
    "    pos =tf.keras.Input(shape=(pos_max,),name=\"pos\")\n",
    "    x=ConvBlock(img,64)\n",
    "    x=ConvBlock(x,128)\n",
    "    x=attend(x,None,4,4)\n",
    "    x=ConvBlock(x,256)\n",
    "    x=ConvBlock(x,512)\n",
    "    x=attend(x,None,8,8,reshape=False)\n",
    "    #------------pos encoding------------------\n",
    "    query=tf.keras.layers.Embedding(input_dim=pos_max+1, output_dim=enc_filters,weights=[pos_emb_weights])(pos)\n",
    "    attn=DotAttention()(query,x,x,None)\n",
    "    x=tf.keras.layers.Dense(voc_len,activation=None,name=\"logits\")(attn)\n",
    "    model = tf.keras.Model(inputs=[img,pos],outputs=x)\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    lr_schedule = tf.keras.experimental.CosineDecay(initial_learning_rate=0.0001,\n",
    "                                                    decay_steps=DECAY_STEPS,\n",
    "                                                    alpha= 0.01)\n",
    "    model = build_model()\n",
    "    if PRETRAINED_WEIGHT_PATHS is not None:\n",
    "        model.load_weights(PRETRAINED_WEIGHT_PATHS)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "                  loss=CharLoss(pad_value),\n",
    "                  metrics=[C_acc])\n",
    "\n",
    "# call back setup\n",
    "model_save=SaveBestModel(model_dir)\n",
    "model_save.set_model(model)\n",
    "callbacks = [model_save,early_stopping]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training \n",
    "* history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_ds,\n",
    "                  epochs=EPOCHS,\n",
    "                  steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                  verbose=1,\n",
    "                  validation_data=eval_ds,\n",
    "                  validation_steps=EVAL_STEPS, \n",
    "                  callbacks=callbacks)\n",
    "\n",
    "curves={}\n",
    "for key in history.history.keys():\n",
    "    curves[key]=history.history[key]\n",
    "curves=pd.DataFrame(curves)\n",
    "curves.to_csv(f\"history.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apsisnetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
